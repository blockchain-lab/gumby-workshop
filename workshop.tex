\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{anysize}
\usepackage{mathtools}
\usepackage{csquotes}
\usepackage{listings}

\usepackage{setspace}
\singlespacing
\onehalfspacing
\doublespacing
\setstretch{1.3} % for custom spacing
\marginsize{2.5cm}{2.5cm}{1cm}{3cm}

\title{Implementing and deploying experiments using Dispersy and Gumby}

\begin{document}

\maketitle

This document describes how to implement and deploy a distributed experiment using Dispersy and Gumby.
After finishing the assignments in this document, you will be able to to:
\begin{itemize}
	\item Send messages to other users in a peer-to-peer network using Dispersy.
	\item Implement and modify a distributed experiment using Gumby. This includes writing your own scenarios and defining experiment modules.
	\item Deploy and execute your experiment on our DAS-5 supercomputer using Gumby.
\end{itemize}

\section{Introduction}
Experimentation lies at the heart of science. They are important to verify hypotheses or to analyse behaviour of algorithms.
In particular, in the field of distributed systems, experiments are often executed at a large scale, involving hundreds of clients producing data and communicating with each other.
Being able to define and run your own experimentations is a valuable skill.

At the distributed systems department and in particular, the blockchain lab, we have created various tools to ease the design and implementation of experiments. In this workshop, we will explore two of these tools, Dispersy and Gumby, and show the practical value of these tools using a basic distributed algorithm that involves cryptographic secret sharing and network communication.
Before elaborating the experiment, we will first introduce Dispersy and Gumby.

\subsection{Dispersy}
Dispersy can be described as a scalable, distributed database, however, it also provides primitives for sending generic messages between users.
Dispersy has the notion of \emph{communities} which are the best described by a group of users that share a common goal or objective.
Some examples of available communities are:
\begin{itemize}
	\item SearchCommunity: This community is responsible for keyword search of content within Tribler, our peer-to-peer filesharing software.
	\item MarketCommunity: This community enables peer-to-peer trading and transaction processing.
\end{itemize}

Creating your own community is straightforward and will be demonstrated in this tutorial.
Dispersy is open-source software and can be downloaded from Github\footnote{https://github.com/tribler/dispersy}.
More information about Dispersy can be found in the technical report\cite{zeilemaker2013dispersy}.

\subsection{Gumby}
Gumby is a framework specifically designed to run experiments.
These experiments can either be executed locally, remotely on a server or on the DAS-5 supercomputer.
Gumby can be downloaded from Github\footnote{https://github.com/tribler/gumby}, however, local experiment execution is only possible on Linux-based environments due to the requirement of \emph{procfs}.
This tutorial will explain the basic concepts in Gumby.

\section{Create Your Experiment}
Start a web browser and navigate to our Jenkins server: https://jenkins.tribler.org.
Jenkins is an open-source software to automate running various jobs like tests or experiments.
These jobs can be executed on machines, which are under \emph{Build Executor Status} 
Here you will see an overview of all the machines that are capable of executing Jenkins jobs (these machines are also called \emph{slaves}).
Take a look at the different machines: the slaves that are prefixed with \emph{DAS5\_} are clusters of the DAS-5 supercomputer.

As you might know, the DAS-5 is not a single machine but shared amongst various universities in the Netherlands.
Each university involved in the DAS-5 project hosts a cluster with a fixed amount of nodes.
Detailed informations including the number of nodes on each cluster and hardware specifications, can be found on the DAS-5 website\footnote{http://www.cs.vu.nl/das5/clusters.shtml}.

Navigate to the \emph{pers} directory on the Jenkins website and locate the job named \emph{workshop\_benaloh\_test}.
We will copy this job so we can modify it accordingly.
To create a copy of an existing job, you should have a valid Jenkins account; if you don't have one, please ask one of the workshop instructors for one.

Start by clicking on the \emph{New Item} in the menu in the upper-left corner of the Jenkins website.
You are now prompted to enter the name of the new job.
Name it something like \emph{workshop\_benaloh\_test\_username} where \emph{username} should be replaced by your Jenkins username or your real name.
Since we copy an existing job, please enter the name of the existing job under the \emph{Copy from} input, at the bottom of the page (which should be \emph{workshop\_benaloh\_test}) and press the \emph{OK} button to confirm.

You will be redirected to the configuration options of the newly created Jenkins job.
Here you can change various settings that are related to your experiment.
Some of the most important experiments will be elaborated now:

\begin{enumerate}
	\item \emph{Restrict where this project can be run}: here you specify on which Jenkins slave you wish to run your job. It should be filled with \emph{DAS5\_TUD}, which is the TU Delft cluster of the DAS-5 supercomputer. You can also select other DAS5 clusters here but the default option should work fine.
	\item \emph{Source Code Management}: this section specifies whether the experiment needs some code from external sources like a VCS (Git, SVN etc) to operate. Our first option specifies that we are using the settings of another Jenkins job here (\emph{Clone\_tribler\_devel}). This makes sure that Tribler is downloaded into the Jenkins workspace since Tribler is a dependency of Gumby. Next, we specify that we want to clone a Git repository, namely the Gumby tutorial. The repository URL is specified, including the git branch that we want to checkout. These options together make sure that we have a copy of Tribler and Gumby ready before the experiment starts.
	\item \emph{Build}: this section indicates the performed actions during the experiment execution. In this case, we run a simple shell script where activate a virtual Python environment (this makes sure that all required Python libraries can be found but it's not very interesting for now). The final line of the bash script starts the Gumby experiment.
	\item \emph{Post-build Actions}: here we specify actions that should be performed after the experiment has finished. In this experiment, we store files in the \emph{output} directory for later usage (this is called archiving). Finally, we create an image gallery from \emph{.png} files.
\end{enumerate}

By pressing the \emph{Save} button at the bottom of the webpage, you save the configuration and return to the overview of the specific job.
You can always return to the configuration overview by clicking the \emph{Configure} menu entry.

When executing a job, a new \emph{build} is created.
Each build has a number of outcomes, including \emph{succeeded} (everything went well), \emph{failed} (something went wrong during the execution of the build) or \emph{aborted} (the job got manually or automatically aborted).
The history of builds is presented under the \emph{Build History} tab on the left.
Here you will see the time, outcome and amount of produced data for each build.

We are now ready to run your newly created job!
Executing jobs can be done by pressing the \emph{Build Now} button in the upper-left menu, please do so now.
Refresh the web page shortly after pressing the button and you will notice that a new entry appears under the \emph{Build History} overview on the left.
You will see a progress bar that indicates the progress of the build.
Click on the build number to navigate to the page with specific details of each build.
We can monitor the progress of each build in detail by clicking on the \emph{Console Output} menu entry on the left.
When the experiment has finished, you will see something similar to the following lines in the log:

\begin{lstlisting}[frame=single]  % Start your code-block
Archiving artifacts
Creating image galleries.Creating archived images gallery.No files found for
image gallery.Started calculate disk usage of build
Finished Calculation of disk usage of build in 0 seconds
Started calculate disk usage of workspace
Finished Calculation of disk usage of workspace in 0 seconds
Notifying upstream projects of job completion
Finished: SUCCESS
\end{lstlisting}

This indicates that the build has succeeded.
We can now investigate the output files of the selected build by going to the \emph{Build Artifacts}.
This opens a basic file explorer where you can navigate through all artifacts generated by the build.
The experiment uses five nodes on the DAS-5 supercomputer and each node writes its output to a directory in \emph{output/localhost}.
If you navigate to \emph{output/localhost}, you will see five directories.
Click on any of them, for instance, \emph{node301}, to view files produced by this node.
Browse the content of the file named \emph{00000.out} which contains the standard out (stdout) output of the processes running on this DAS-5 node.
You should see the following lines:

\begin{lstlisting}[frame=single]
My computed sum is 656
My secret value is 722
\end{lstlisting}

The computed sum should be the same for all nodes but the secret values are (probably) different.

\section{The Benaloh Experiment}
In this exercise we will be implementing a simplified version of the Benaloh secret sharing scheme.
You can find the complete code of this exercise on GitHub\footnote{https://github.com/qstokkink/gumby/tree/workshop\_code/experiments/benaloh}.
In particular we will focus on the different ways to share data and not so much on the security or efficiency of the algorithm.
The protocol we will implement is as follows:

\begin{enumerate}
\item Every node starts with a globally known node count $n$ and modulus $M$ and a private share $s$.
The nodes then generate $n-2$ random numbers $R$ and calculates $s - \Sigma R$ individually.
\item Every node shares all values from step $1$ \textbf{directly} with all other nodes.
\item Every node sums all the received values from step $2$ and \textbf{broadcasts} this value to all other nodes.
\item All nodes print the sum of all received values from step $3$.
\end{enumerate}

\subsection{The Dispersy Community}
\noindent The community which provides the functionality described above is given here:

https://github.com/qstokkink/gumby/blob/workshop\_code/experiments/benaloh/benaloh\_community.py

\vspace{\baselineskip}
\noindent Globally this Dispersy Community has the following components it needs to make it work:

\begin{itemize}
\item A \texttt{Payload} object, representing packets going over the network.
\item A \texttt{Conversion} object, which can transform \texttt{Payload} objects into binary data.
\item A \texttt{Community} object which handles incoming \texttt{Payload} objects and provides functionality to send \texttt{Payload} objects.
\end{itemize}

\noindent The finer details of creating these objects will remain out of the scope of this document, but we would like to draw the attention of the reader to the different types of messages defined in the \\\texttt{BenalohCommunity.initiate\_meta\_messages()} function.

The first type of message you will find defined in the community file is a \textbf{broadcast} message using Dispersy's gossiping: \texttt{u"broadcast-share"}.
This message uses \texttt{MemberAuthentication}, which means that every message will be signed  and verified when received.
The alternative to \texttt{MemberAuthentication} is \texttt{NoAuthentication}.
Next, you will see \texttt{FullSyncDistribution(u"ASC", 128, False)}, this takes care of stamping your message with a global time and which avoids duplicate messages.
Besides this the \texttt{FullSyncDistribution} definition also serves as a flag to tell Dispersy that your message needs to be gossiped throughout the network.
The \texttt{CommunityDestination(10)} directive then tells Dispersy that your message will be gossiped using a fanout of $10$ neighboring nodes.
Lastly, \texttt{self.on\_broadcast\_share} tells Dispersy which function handles incoming messages of the \texttt{u"broadcast-share"} persuasion.

The other message in this file is the \texttt{u"local-share"} message.
This message can be sent directly to other known peers.
You will notice that the difference between the two messages lies in the declaration of the \texttt{DirectDistribution} and \texttt{CandidateDestination}.
These two flags let Dispersy know that you want to directly send this message to others and you will be the one in charge of supplying the peers/candidates to send it to.

One observation you will make is that it is much faster to send to other candidates directly instead of gossiping it using a broadcast.
Still, it would not be wise, even erroneous, to use the supplied code outside of Gumby.\\
\\
\textbf{Questions/exercises:}
\begin{enumerate}
\item \textit{Why is the supplied code not scalable?}
\item \textit{Find the two race conditions in the message delivery which can cause incorrect algorithm execution.}
\item \textit{Do the two messages have a different wire format?}
\end{enumerate}

\bibliographystyle{plain}
{\small \bibliography{workshop}}

\end{document}
